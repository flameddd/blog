## Redis
今天主要講 `cache` 跟 `hot data` 兩個重點。  
redis 是 `single thread` 的。  
你的 operation 是 Ｏ(1) 的，當然很ＯＫ  
如果是 Ｏ(n) 或 Ｏ(wholeDB) 通常會死掉。因為 redis 是 `single thread!!!` 的。  
Redis Zrange 代表每次的 operation Ｏ(nlogN) 的。

## 一致性
只有 relation db 能處理這種 multi state, multi record 的情況
1. begin TX
2. TX update uesrA balance - 100
3. TX update userB balance + 100
4. end TX

## 2 phase commit
3台 redis
redis1 存Ａ資料
redis2 存Ｂ資料
Ａ轉錢給Ｂ、 2 phase commit 代表你的 data 要 lock 在那邊。
你的 data 就沒有 avaiability。

## 2 選 1
1. Presistence 當機後，資料不會 lose
2. Low latency 資料庫極短時間能完成單一工作
只能同時滿足1個。
Redis 是追求 low latency。
如果 data 可以不見的話， memory db 是當然可以用的。
mongDB 3.1 版的 default setting，回傳 OK 時，只代表寫到 memory裡面。
還沒寫到 disk 中，所以跑分才這麼高。

## Redis
default presistis mode 是 10000 個 write 才會寫入 harddisk 中。
而且回傳 OK 時，也不是保證有到 disk 。這時候如果 power down 的話，會有些 data lose 的。
如果跟錢有關的話，千萬不要用 redis

## caching 常犯錯誤
### local cache
 系統非常小的話，很多常用 local cache。local cache 是指 application server 上的 local memory。
 很多 ORM 都有 caching 功能。  
 `不可以單純只用 AS 的 local cache`。  
  - 缺點：改動沒法反映到全部伺服器上，所以有機會用上舊的版本。
  - AS 的 local cache 不能隨流量加大，系統流量越大，cache miss 可能性越高。
  - `新開的 AS 的 local cache 是全部空的`
 這樣新的 AS 就會把 request 打到 DB 的！（就是在系統資源不足時，我們新開機器。新開機器，我們都會把新的流量導過去。導過去，但又沒有 cache ，所以會打到 DB 。這樣 DB 很容易掛。
 這就是 `只用` local cache 的缺點。

 通常流量越高，我們需要 cache 的空間需要越高。但只用 local cache 的話，你的容量固定只有那幾 GB，沒有辦法往上拉的話，你 cache 的效果就越來越差。

 local cache 當然可以做為 extra cache ，但主要還是需要外面有一台。

### 「一般」的 caching
1. 存 redis 拿 data X ，如果有就會傳。（如果沒有
2. 從 db 拿 data X
3. 存回到 redis
4. redis 回傳 data X

結果！？約會時救火。  
如果這份 data 是很多人要的 data ，有 1000 人要這份 data、從 db 需要 100ms 取回資料X
在這 `100ms` 時間內，所有人（1000人）都是 miss cache 的。 main db 的流量瞬間爆上去

＿｜＿｜＿｜ ＜＝會長這樣。

如果有 max connection 的情況下的話才能穩。不然大家同時間站進來 1000 人的話，死吧。
如果這筆 data 是 heavily calculation 的話 ＝＞ 炸

有2個手段處理。
 - pre cache 非常重要，每X分鐘 我就先算好結果丟到 redis中。 看起來很笨，但很好用！
 - 高流量下的 caching

### 高流量下的 caching
 pre cache 的手段不管用，因為沒法所有的東西都丟到 cache 中。高流量是指 C10K 左右。
 1. 從 redis 拿 dataX；如果有直接回傳
 2. 拿到 dataX 的 lock(在離開時釋放)  ＜＝＝ 重點！保護 如果拿相同的 data 的話，只有1人可以進來 db （保證同一份 data 在同一時間只有1個人可以讀、99人被擋住 靠 step3 拿資料）
 3. 再次從 redis 拿 dataX；如有則直接回傳
 4. 從 db 拿 dataX
 5. 把 dataX 放回 redis
 6. dataX 回傳

 step2 時，還要確認資料不是正確的。  

### 沒使用 consistency hash
 - 別使用 mod(md5(cacheKey), n)來決定某一 key value 的位置 （多台 redis 的情況）
 - n = 你的 redis server 總數
 - 上面這招 10年前的招式。
 - 用這招，當 loading up 時，加開 redis 時，n 改動會讓你的 caching 全滅

這真是他媽的，這時候 cache 全部 miss、全部改成打到 db 去，他媽的又掛了。  

 - 請學習 `consistent hash`（redis cluster 內建了）  

system 503 通常是有人為耍蠢做了什麼事情。  
也就是說，不要自己算 hash。  

3台 redis 時、每台 33% 資料。加開一台 redis 時，理想是這3台各 8% 轉到第4台。  
consistent hash 的 就會轉移。 這 case 的情況下當下會有 25% cache miss  
如果機器是 20 台的話，就 5% 的 cache miss。  

redis 有個 middleware （有名的？）幫忙做 consistent hash。

### redis 的 lur script
 - lur script 的 array 是...  待會說

### 用作 locking server
 - 專業應用請用 `Zookeeper` or `etcd`
 - redis 沒法做到 blocking，要做到 globle locking 的話，要用上面的
 - 指令：SET <lockName> <anystring> NX EX <lockTime>
 - 如果不成功，則用 for loop 重試 （缺點  如果這個 lock 很多人請的話， 100人一直來 for loop 來 re try、浪費 CPU、沒法保證 first in, first out 下一個不知道誰拿到 lock）
 所以 redis 沒辦法保證公平性。

 - 關鍵字： exponential backoff、jitter  讓 sleep 的時間是個 random 讓所有人的等待時間綽開。每次 sleep 的 time 稍微長一點。

## MQ server
 - MQ 專業請用 RabbitMQ
 - redis 沒法保證 blocking （後面的工作在等待時，會吃 CPU，因為會一直來問有沒有空、換我了沒？）
 - 沒法保證工作（成功保一次 + single thread）
 - 更沒有辦法保證 data lose
 - 簡單用 list
 - 進階用 set
  能讓高優先工作先執行、增加工作用 SADD、拿工作出來用 SRANDMEMBER 然後 SREM。

專業 MQ 會確認 task 有做完。task 做完會回傳訊息給 MQ、MQ 才會 delete task  

## 高流量下 redis 各種賤招 C10K
 - 不管 redis cluster 有多少個 node，一份資料只能存在一台 redis 上
 - 如果這份資料有 C100K 的流量，存了那份資料的 redis 必檔。
 - 我們的實戰經驗，單台的 redis 大約能支持 C10K。 (docker、簡單的 operation)

多份資料的話，可能會失去 consisitant

 - 之前說過了，可以用 pre caching 的技巧。 landing page 的data 很有可能全部都上 cache
每分鐘 re calculate 一份放到 redis 去。很笨 但有用。

## 案例分享
 - 現在有 C100K QPS 想來購買某商品。但是系統每一商品只能有 100 QPS 處理能力。
 - nginx 的 ratelimiting 是以 api 為單位的 （捨棄 10%客戶，總比系統整個死。台電分區限電）
  這其實對一般系統很夠用了。
 - ratelimiting 常用算法： token bucket
  以 hash 存 remainingTokenCount 和 lastUpdateTime

突然暴漲 20倍 流量時，怎麼 auto scaling。
先開好 instance ，然後備援也要進來。

### 善用 local buffering/ cachine
 - 如果每一個 request 都要詢問 redis 的話，C50K 下必死。
 - 如果 Application Server 每次不是拿一個 token，而是 10 個
  - 剩下9個 token 留給未來用。
  - redis QPS 會變成 1/10
  - JWT 是可以有 userID 的 能判斷
  如果 Application Server 一個 token 也拿不到，乾脆拒絕所有同類 request。

  所以流量高的時候，應該是 之前 exist 的 user 還可用，新進來的 user 要擋住。

 更好的應該做 system throltting （後進來的 user 晚點幫他處理）
 
他們用 bloomfilter 來記錄 這個token 15分鐘內有沒有來過。有的話他就是 existing user
那我在高流量時，我就不要捨棄他們，而是捨棄新進來的用戶。

只要在高流量的情況下，是做不到公平的。

